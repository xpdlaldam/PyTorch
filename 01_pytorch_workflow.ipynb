{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmaJxG0m9/sR9DSlmX8rFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xpdlaldam/PyTorch/blob/main/01_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "u9mi4zQCP6hQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUBkjCcokN_q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn ## nn contains all of pytorch's building blocks for nerual networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create known parameters\n",
        "weight = .7\n",
        "bias = .3\n",
        "\n",
        "# Create data & model\n",
        "start = 0\n",
        "end = 1\n",
        "step = .02\n",
        "\n",
        "## unsqueeze(dim=1)\n",
        "# adds 1-D i.e., [ => [[\n",
        "# we need 2-D for modeling\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "y"
      ],
      "metadata": {
        "id": "GDu0oEYSlteF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(start, end, step)"
      ],
      "metadata": {
        "id": "4FM1y01rQWnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split to train & test"
      ],
      "metadata": {
        "id": "wf_OyPfZRgiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = int(.8 * len(X))\n",
        "X_train, y_train = X[:split_ratio], y[:split_ratio]\n",
        "X_test, y_test = X[split_ratio:], y[split_ratio:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "YdAN9gsEQc9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "c_MDgdnCTud6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(\n",
        "    train_data=X_train,\n",
        "    train_labels=y_train,\n",
        "    test_data=X_test,\n",
        "    test_labels=y_test,\n",
        "    pred=None,\n",
        "):\n",
        "  \"\"\"\n",
        "  Plots training & test data and compares against predictions\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Train set\") # plots train set\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Test set\") # plots train set\n",
        "\n",
        "  # are there predictions?\n",
        "  # if pred: # this checks if pred is True\n",
        "  if pred is not None: # this checks only the reference pred with None to see if they are the same\n",
        "    plt.scatter(test_data, pred, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # legend\n",
        "  plt.legend(prop={\"size\": 14})\n"
      ],
      "metadata": {
        "id": "N8PGonJ6TJBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred()"
      ],
      "metadata": {
        "id": "jZMxBYhnVddH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build model"
      ],
      "metadata": {
        "id": "tVVPPM9v-qRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "## nn.Module:\n",
        "  # almost everything in pytorch inherits nn.module\n",
        "  # subclasses nn.Module which contains all the building blocks for neural networks\n",
        "## 1: start with a random weight\n",
        "## requires_grad=True: can this parameter be updated via gradient descent?\n",
        "## dtype=torch.float: pytorch loves torch.float32\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    ## Initialize model parameters\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float)) # default: float32\n",
        "\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "  # Forward\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # x is the input data (tensor)\n",
        "    return self.weights * x + self.bias"
      ],
      "metadata": {
        "id": "mafAyf-YViCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch model building essentials\n",
        "\n",
        "* torch.nn - contains all the buildings for computational graphs i.e., a neural network\n",
        "* torch.nn.Parameter - what parameters should our model try and learn, often a pytorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should override forward()\n",
        "* torch.optim - this is where optimizers in pytorch lives which helps with gradient descent i.e., instead of random initialization\n",
        "* def forward() - all nn.Module subclasses require you to override"
      ],
      "metadata": {
        "id": "pIGZVjOID9yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(1)"
      ],
      "metadata": {
        "id": "oIDvagdrG9_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "lin_reg = LinearRegressionModel()\n",
        "list(lin_reg.parameters())"
      ],
      "metadata": {
        "id": "ytKZMsNzEALN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list named parameters\n",
        "lin_reg.state_dict()"
      ],
      "metadata": {
        "id": "09TqXOaHGuXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict using `torch.inference_mode()`"
      ],
      "metadata": {
        "id": "ZWeTnSygipLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "aHHR-5GCi4Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "oXRFYDRni8fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## * CRUCIAL CONCEPT & TIP: Benefits of using a context manager\n",
        "# Turns off/disables gradient => because we're only doing inference, we don't need to track gradient\n",
        "# This context manager becomes useful when we have a much larger dataset\n",
        "# The prediction will be much faster than w/o using a context manager as it disables unnecessary steps used for training\n",
        "# lin_reg(X_test) leaves the gradient\n",
        "with torch.inference_mode():\n",
        "  y_preds = lin_reg(X_test)\n",
        "\n",
        "# or\n",
        "# ctrl + /\n",
        "# with torch.no_grad():\n",
        "#   y_preds = lin_reg(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "SC67PfT3Hryo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(pred=y_preds)"
      ],
      "metadata": {
        "id": "DU5Yg-vDjiHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "* note: loss function = cost function = criterion\n",
        "\n",
        "Things we need to train:\n",
        "* **Loss function**:\n",
        "* **Optimizer**: Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias)\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "ure-tJXsfADO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Setup a loss function\n",
        "loss_fn = nn.L1Loss() # MAE\n",
        "\n",
        "## parameter vs hyperparameter\n",
        "# parameter - the model finds it\n",
        "# hyperparameter - the data scientists define it\n",
        "\n",
        "## Setup an optimizer\n",
        "# params - the model parameters you'd like to optimize\n",
        "# lr - a hyperparameter that defines the magnitude of change for the optimizer with each step\n",
        "optimizer = torch.optim.SGD(\n",
        "    params=lin_reg.parameters(),\n",
        "    lr=.01\n",
        ") # SGD"
      ],
      "metadata": {
        "id": "NjnstjKdkH1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a training loop in pytorch\n",
        "\n",
        "## What we need in a training loop\n",
        "0. Loop through the data\n",
        "1. Forward pass/propagation to make predictions\n",
        "2. Compute the loss: compare forward pass predictions vs ground truth\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward / **backpropagation** - computes the gradients of each of the parameters with respect to the loss\n",
        "5. Optimizer step / **gradient descent** - adjusts our model's parameters to improve the loss"
      ],
      "metadata": {
        "id": "HhWCXUcvvcFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch: one loop through the data (a hyperparameter); a single forward pass\n",
        "epochs = 200\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "### Train\n",
        "# 0.\n",
        "for epoch in range(epochs):\n",
        "  lin_reg.train() # set the model to training mode which sets all parameters to require gradients\n",
        "\n",
        "  ## 1. forward pass\n",
        "  y_pred = lin_reg(X_train)\n",
        "\n",
        "  ## 2. loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  # print(f\"Loss: {loss}\")\n",
        "\n",
        "  ## 3. optimizer zero grad\n",
        "  # starts fresh\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  ## 4. backpropagation - on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  ## 5. step the optimizer (perform gradient descent)\n",
        "  # by default, how the optimizer changes will accumulate\n",
        "  # through the loop, hence we have to zero them in step 3\n",
        "  # for the next iteration of the loop\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing mode\n",
        "  lin_reg.eval() # turns off different settings in the model not needed for testing (ex) dropout, batch norm layers)\n",
        "  with torch.inference_mode(): # turns off gradient tracking + a couple more things behind\n",
        "    # 1. forward pass\n",
        "    test_pred = lin_reg(X_test)\n",
        "\n",
        "    # 2. compute the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  if epoch & 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoch} | Test: {loss} | Test loss: {test_loss}\")\n",
        "    print(lin_reg.state_dict())"
      ],
      "metadata": {
        "id": "sWyTpdmzkf4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values"
      ],
      "metadata": {
        "id": "ZZyJL9gn8IRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_values"
      ],
      "metadata": {
        "id": "pg-Ok1QJ8Lk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot loss curve\n",
        "# plt.plot(epoch_count, loss_values, label=\"Train Loss\") # Need to convert tensor type from loss_values to numpy to plot\n",
        "\n",
        "import numpy as np\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train Loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test Loss\")\n",
        "plt.title(\"Train & Test Loss Curves\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "1Xc0Ed3p7cbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = lin_reg(X_test)"
      ],
      "metadata": {
        "id": "J1sVDTzspGnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg.state_dict()"
      ],
      "metadata": {
        "id": "wdNLxSaX51N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(pred=y_preds)"
      ],
      "metadata": {
        "id": "z_AagtnGqMoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(pred=y_preds_new)"
      ],
      "metadata": {
        "id": "IT8m8HExqcCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving a model in pytorch"
      ],
      "metadata": {
        "id": "PAGWQUcYU0l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg.state_dict()"
      ],
      "metadata": {
        "id": "vzAqrpuZU3QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create model directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True) # exist_ok=True - if the dir already exists, it won't throw an error\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\" # A common pytorch convention is to save models using either a .pt or .pth file extension\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "MODEL_SAVE_PATH\n",
        "\n",
        "# Save state_dict()\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=lin_reg.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "icQ2kJ73WDMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "id": "OHnJy56gX3hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading a model in pytorch"
      ],
      "metadata": {
        "id": "hCVm2XpnFYXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_lin_reg = LinearRegressionModel() # a subclass of NN.Module\n",
        "loaded_lin_reg.state_dict()"
      ],
      "metadata": {
        "id": "gPrZKDmXYFLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_lin_reg.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "id": "ax5tBrX_F0tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_lin_reg.state_dict()"
      ],
      "metadata": {
        "id": "0aIJsbsIGjat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_lin_reg.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_lin_reg(X_test)\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "id": "Icup4ryIGltl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_lin_reg.eval()\n",
        "with torch.inference_mode():\n",
        "  model_preds = lin_reg(X_test)\n",
        "model_preds"
      ],
      "metadata": {
        "id": "UOlMIymPG3oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_preds == model_preds"
      ],
      "metadata": {
        "id": "4-TQrJ6NHQNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Data"
      ],
      "metadata": {
        "id": "mxlnkjndH9Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias"
      ],
      "metadata": {
        "id": "v0b6x7T3H-2s"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRJUBtIwIDhe",
        "outputId": "5b219a41-fb15-4f66-a0f5-f39f156d1b3f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2. Build pytorch Linear Model (this time using nn.Linear())"
      ],
      "metadata": {
        "id": "adlUJtuRT7It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "wkaviqdzA8TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "## nn.Module:\n",
        "  # almost everything in pytorch inherits nn.module\n",
        "  # subclasses nn.Module which contains all the building blocks for neural networks\n",
        "## 1: start with a random weight\n",
        "## requires_grad=True: can this parameter be updated via gradient descent?\n",
        "## dtype=torch.float: pytorch loves torch.float32\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    ## Use nn.Linear() for creating model parameters\n",
        "    # torch.nn.Linear() - applies a linear transformation to the incoming data:\n",
        "    # y = xA` + b\n",
        "    # in_features=1\n",
        "      # number of input data dimensions\n",
        "      # 1 input feature (x) as we're modeling a simple linear regression\n",
        "    # out_features=1:\n",
        "      # number of output data dimensions\n",
        "      # 1 output feature (y) as we're modeling a univariate model\n",
        "    self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
        "\n",
        "  # Forward\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # x is the input data (tensor)\n",
        "    return self.linear_layer(x)"
      ],
      "metadata": {
        "id": "uIVmngyRHUoL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Need to execute this line to start over before the training loop starts\n",
        "torch.manual_seed(42)\n",
        "lin_reg = LinearRegressionModel()\n",
        "lin_reg, lin_reg.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFAaa3YaVFGx",
        "outputId": "ce9b15d4-11f6-4fda-8a06-29711bc10ecc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearRegressionModel(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(lin_reg.parameters())"
      ],
      "metadata": {
        "id": "RGg8wTA8BTew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(lin_reg.parameters()).device"
      ],
      "metadata": {
        "id": "qqH7NY5uBJP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to use the target device\n",
        "lin_reg.to(device)\n",
        "next(lin_reg.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUYUTPVmBQ0K",
        "outputId": "88c2399e-0590-4147-b9b4-88b00b7f89b5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.3. Training"
      ],
      "metadata": {
        "id": "tUQq68YSB7Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Need to execute this line to start over before the training loop starts\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params=lin_reg.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "jIwy4xtCHp2i"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch: one loop through the data (a hyperparameter); a single forward pass\n",
        "epochs = 200\n",
        "\n",
        "# Put data on the target device(device-agnostic code for data) => error w/o this part\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  ### Training\n",
        "  lin_reg.train()\n",
        "  y_pred = lin_reg(X_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # Update the parameters with requires_grad=True w.r.t the loss gradients to improve them\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing mode\n",
        "  lin_reg.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = lin_reg(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMWJPXqZB0qs",
        "outputId": "5bedd837-e9ae-4366-8bbf-763893c8d443"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 10 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 20 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 30 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 40 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 50 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 60 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 70 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 80 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 90 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 100 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 110 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 120 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 130 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 140 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 150 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 160 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 170 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 180 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
            "Epoch: 190 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLvbCXN1HQCJ",
        "outputId": "abfab25f-6903-4ba1-abfe-def4b11ab700"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6968]])),\n",
              "             ('linear_layer.bias', tensor([0.3025]))])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHQ85xD_K_Pw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}